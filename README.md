# ğŸ§  KTP - Knowledge Transfer Platform

A collaborative platform designed to simplify and streamline technical knowledge sharing within teams. KTP integrates data from multiple sources (GitHub, Notion, Slack) and provides intelligent search and Q&A capabilities powered by AI.

## âœ¨ Features

- **ğŸ” Intelligent Search**: Semantic search across all your knowledge sources
- **â“ AI-Powered Q&A**: Ask questions and get intelligent answers with sources
- **ğŸ”— Multi-Source Integration**: Connect GitHub, Notion, and Slack
- **ğŸ”„ Automatic Deduplication**: Smart content deduplication across sources
- **ğŸ“Š Real-time Analytics**: View statistics and insights about your knowledge base
- **ğŸ¨ Modern UI**: Beautiful Streamlit-based interface
- **ğŸš€ One-Click Integration**: Integrate all sources with a single click

## ğŸ—ï¸ Architecture

- **Backend**: Flask API with OpenAI embeddings and Pinecone vector database
- **Frontend**: Streamlit web application
- **AI**: OpenAI GPT-3.5-turbo for Q&A and text-embedding-3-small for embeddings
- **Database**: Pinecone vector database for semantic search
- **Integrations**: GitHub API, Notion API, Slack API

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- OpenAI API key
- Pinecone API key
- (Optional) GitHub, Notion, and Slack tokens

### Installation

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd ktp
   ```

2. **Install dependencies**
   ```bash
   pip install -r server/requirements.txt
   ```

3. **Set up environment variables**
   ```bash
   cp server/.env.example server/.env
   # Edit server/.env with your API keys
   ```

4. **Start the application**
   ```bash
   python run_ktp.py
   ```

5. **Access the application**
   - Frontend UI: http://localhost:8501
   - Backend API: http://localhost:5000

## ğŸ“‹ Environment Variables

Create a `.env` file in the `server` directory:

```env
# Required
OPENAI_API_KEY=your_openai_api_key
PINECONE_API_KEY=your_pinecone_api_key
PINECONE_INDEX_NAME=your_pinecone_index_name

# Optional - for integrations
GITHUB_TOKEN=your_github_token
NOTION_TOKEN=your_notion_token
SLACK_BOT_TOKEN=your_slack_bot_token
```

## ğŸ¯ Usage

### Frontend Interface

The Streamlit frontend provides an intuitive interface for:

1. **ğŸ  Dashboard**: System overview and quick actions
2. **ğŸ“š Knowledge Base**: Upload and manage content
3. **ğŸ” Search**: Search through your knowledge base
4. **â“ Q&A**: Ask questions and get AI-powered answers
5. **ğŸ”— Integrations**: Connect external data sources
6. **ğŸ“Š Statistics**: View analytics and insights

### API Endpoints

- `GET /health` - Server health check
- `POST /ingest` - Upload text content
- `POST /ingest/file` - Upload file content
- `POST /search` - Search knowledge base
- `POST /ask` - Ask questions
- `POST /integrate/github` - GitHub integration
- `POST /integrate/notion` - Notion integration
- `POST /integrate/slack` - Slack integration
- `POST /integrate/all` - One-click integration
- `GET /stats` - Get statistics

## ğŸ”— Integrations

### GitHub Integration
- Reads repository content (README, code files, issues)
- Supports both public and private repositories
- Automatic text file detection and processing

### Notion Integration
- Reads pages and database entries
- Supports workspace-wide page discovery
- Handles rich text and structured content

### Slack Integration
- Reads channel messages and conversation history
- Supports direct messages and search
- Automatic message content extraction

## ğŸ§  AI Features

### Semantic Search
- Uses OpenAI embeddings for semantic understanding
- Configurable similarity thresholds
- Source and type filtering

### Intelligent Q&A
- RAG (Retrieval-Augmented Generation) system
- Context-aware answers with source citations
- Configurable number of sources

### Content Deduplication
- MD5-based content hashing
- Source priority system (GitHub > Notion > Slack)
- Automatic duplicate detection and removal

## ğŸ“Š Analytics

The platform provides comprehensive analytics:

- Total vectors in the knowledge base
- Source breakdown (GitHub, Notion, Slack)
- Content type distribution
- Integration statistics
- Deduplication metrics

## ğŸ› ï¸ Development

### Project Structure
```
ktp/
â”œâ”€â”€ server/                 # Flask backend
â”‚   â”œâ”€â”€ app.py             # Main Flask application
â”‚   â”œâ”€â”€ routes/            # API route definitions
â”‚   â”œâ”€â”€ utils/             # Utility modules
â”‚   â””â”€â”€ requirements.txt   # Python dependencies
â”œâ”€â”€ frontend/              # Streamlit frontend
â”‚   â”œâ”€â”€ streamlit_app.py   # Main Streamlit application
â”‚   â””â”€â”€ README.md          # Frontend documentation
â”œâ”€â”€ run_ktp.py            # Startup script
â””â”€â”€ README.md             # This file
```

### Running in Development

```bash
# Terminal 1: Start Flask backend
cd server
python app.py

# Terminal 2: Start Streamlit frontend
cd frontend
streamlit run streamlit_app.py
```

### Testing

```bash
# Test the complete system
python test_deduplication_system.py

# Test the Streamlit frontend
python test_streamlit_frontend.py
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- OpenAI for AI capabilities
- Pinecone for vector database
- Streamlit for the frontend framework
- Flask for the backend framework

## ğŸ“ Support

For support and questions, please open an issue in the repository. 